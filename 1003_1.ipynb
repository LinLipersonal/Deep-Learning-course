{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3133ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.4.0\n",
      "Keras Version: 2.4.0\n",
      "\n",
      "Python 3.8.13 (default, Mar 28 2022, 06:16:26) \n",
      "[Clang 12.0.0 ]\n",
      "Pandas 1.4.4\n",
      "Scikit-Learn 1.1.1\n",
      "GPU is NOT AVAILABLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-08 21:42:29.554428: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e04c593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa89bfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdf4963d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "035d04ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2886ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "707a5e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da12c34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe256639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93999bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-08 21:49:01.393267: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e022575",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7d10250",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "423d58c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-08 21:49:54.599681: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.4149 - accuracy: 0.8787\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1126 - accuracy: 0.9676\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0687 - accuracy: 0.9793\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0476 - accuracy: 0.9848\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0345 - accuracy: 0.9892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe12c87d430>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5d3c0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9694127e-08, 6.1087779e-10, 1.5124383e-06, 1.1943932e-04,\n",
       "       3.0480989e-12, 1.3031389e-07, 1.2117027e-13, 9.9987733e-01,\n",
       "       1.2346746e-07, 1.3816251e-06], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digits = test_images[0:10]\n",
    "predictions = model.predict(test_digits)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b51cd630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28a66db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99987733"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "577f91a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "112205bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 887us/step - loss: 0.0669 - accuracy: 0.9789\n",
      "test_acc: 0.9789000153541565\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"test_acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fc08621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7c85386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e44f38d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  3,  6, 14,  7])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([12, 3, 6, 14, 7])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "765633fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4ea46f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7213389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c626d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fff06f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22bf5d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bc10ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91aeda0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "digit = train_images[5]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e250fb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aab1dd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "431ea0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, :, :]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8cd3e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d08095ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_slice = train_images[:, 14:, 14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28953a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_slice = train_images[:, 7:-7, 7:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f0aa4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train_images[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "946d1362",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train_images[128:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5aef29b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "batch = train_images[128 * n:128 * (n + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44114c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9cfe718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert x.shape == y.shape\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d9b2c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.01 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x = np.random.random((20, 100))\n",
    "y = np.random.random((20, 100))\n",
    "\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = x + y\n",
    "    z = np.maximum(z, 0.)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b9b10a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 1.97 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = naive_add(x, y)\n",
    "    z = naive_relu(z)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23aae168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.random.random((32, 10))\n",
    "y = np.random.random((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89a507d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.expand_dims(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b411433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.concatenate([y] * 32, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef22788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add_matrix_and_vector(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[j]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e8c9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.random.random((64, 3, 32, 10))\n",
    "y = np.random.random((32, 10))\n",
    "z = np.maximum(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0180e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((32,))\n",
    "y = np.random.random((32,))\n",
    "z = np.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "38a65b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69ee1779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b03595f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = naive_vector_dot(x[i, :], y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eaf4ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros((x.shape[0], y.shape[1]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b57c34a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6732a7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0., 1.],\n",
    "             [2., 3.],\n",
    "             [4., 5.]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5bd919e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((6, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "124b306b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 300)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16f57652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(0.)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "10eebca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(tf.random.uniform((2, 2)))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "913bf1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random.uniform((2, 2)))\n",
    "b = tf.Variable(tf.zeros((2,)))\n",
    "x = tf.random.uniform((2, 2))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.matmul(x, W) + b\n",
    "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9ed11671",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6f7bbe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "46bc9ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8225004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.4302 - accuracy: 0.8744\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1122 - accuracy: 0.9671\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0703 - accuracy: 0.9782\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0486 - accuracy: 0.9857\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0347 - accuracy: 0.9895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe120c4d400>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ef77919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class NaiveDense:\n",
    "    def __init__(self, input_size, output_size, activation):\n",
    "        self.activation = activation\n",
    "\n",
    "        w_shape = (input_size, output_size)\n",
    "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
    "        self.W = tf.Variable(w_initial_value)\n",
    "\n",
    "        b_shape = (output_size,)\n",
    "        b_initial_value = tf.zeros(b_shape)\n",
    "        self.b = tf.Variable(b_initial_value)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.W, self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3e30da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveSequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers:\n",
    "           x = layer(x)\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "       weights = []\n",
    "       for layer in self.layers:\n",
    "           weights += layer.weights\n",
    "       return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "55b8f373",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveSequential([\n",
    "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
    "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
    "])\n",
    "assert len(model.weights) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e63327d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, batch_size=128):\n",
    "        assert len(images) == len(labels)\n",
    "        self.index = 0\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = math.ceil(len(images) / batch_size)\n",
    "\n",
    "    def next(self):\n",
    "        images = self.images[self.index : self.index + self.batch_size]\n",
    "        labels = self.labels[self.index : self.index + self.batch_size]\n",
    "        self.index += self.batch_size\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56769181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_training_step(model, images_batch, labels_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images_batch)\n",
    "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            labels_batch, predictions)\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "    gradients = tape.gradient(average_loss, model.weights)\n",
    "    update_weights(gradients, model.weights)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de90b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    for g, w in zip(gradients, weights):\n",
    "        w.assign_sub(g * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "34bef6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    optimizer.apply_gradients(zip(gradients, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8d8693dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, images, labels, epochs, batch_size=128):\n",
    "    for epoch_counter in range(epochs):\n",
    "        print(f\"Epoch {epoch_counter}\")\n",
    "        batch_generator = BatchGenerator(images, labels)\n",
    "        for batch_counter in range(batch_generator.num_batches):\n",
    "            images_batch, labels_batch = batch_generator.next()\n",
    "            loss = one_training_step(model, images_batch, labels_batch)\n",
    "            if batch_counter % 100 == 0:\n",
    "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506dd813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "loss at batch 0: 0.65\n",
      "loss at batch 100: 0.66\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "fit(model, train_images, train_labels, epochs=11, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d0353ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "predictions = model(test_images)\n",
    "predictions = predictions.numpy()\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "matches = predicted_labels == test_labels\n",
    "print(f\"accuracy: {matches.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5ab4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
